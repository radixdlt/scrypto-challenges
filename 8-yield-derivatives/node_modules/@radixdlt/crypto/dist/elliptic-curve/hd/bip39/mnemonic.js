"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.Mnemonic = exports.byteCountFromEntropyStrength = exports.entropyInBitsFromWordCount = exports.strengthFromWordCount = exports.mnemonicStrengthSupportedByBIP39 = exports.languagesSupportedByBIP39 = exports.wordlistFromLanguage = void 0;
const neverthrow_1 = require("neverthrow");
const _types_1 = require("./_types");
const bip39_1 = require("bip39");
const util_1 = require("@radixdlt/util");
const wordlistFromLanguage = (language) => {
    const key = _types_1.LanguageT[language].toLowerCase();
    return bip39_1.wordlists[key];
};
exports.wordlistFromLanguage = wordlistFromLanguage;
exports.languagesSupportedByBIP39 = [
    _types_1.LanguageT.CZECH,
    _types_1.LanguageT.CHINESE_SIMPLIFIED,
    _types_1.LanguageT.CHINESE_TRADITIONAL,
    _types_1.LanguageT.KOREAN,
    _types_1.LanguageT.FRENCH,
    _types_1.LanguageT.ITALIAN,
    _types_1.LanguageT.SPANISH,
    _types_1.LanguageT.JAPANESE,
    _types_1.LanguageT.ENGLISH,
];
exports.mnemonicStrengthSupportedByBIP39 = [
    _types_1.StrengthT.WORD_COUNT_12,
    _types_1.StrengthT.WORD_COUNT_15,
    _types_1.StrengthT.WORD_COUNT_18,
    _types_1.StrengthT.WORD_COUNT_21,
    _types_1.StrengthT.WORD_COUNT_24,
];
const separator = ' ';
const strengthFromWordCount = (wordCount) => wordCount === 24
    ? (0, neverthrow_1.ok)(_types_1.StrengthT.WORD_COUNT_24)
    : wordCount === 21
        ? (0, neverthrow_1.ok)(_types_1.StrengthT.WORD_COUNT_21)
        : wordCount === 18
            ? (0, neverthrow_1.ok)(_types_1.StrengthT.WORD_COUNT_18)
            : wordCount === 15
                ? (0, neverthrow_1.ok)(_types_1.StrengthT.WORD_COUNT_15)
                : wordCount === 12
                    ? (0, neverthrow_1.ok)(_types_1.StrengthT.WORD_COUNT_12)
                    : (0, neverthrow_1.err)(Error(`Unsupported wordcount ${wordCount}`));
exports.strengthFromWordCount = strengthFromWordCount;
const entropyInBitsFromWordCount = (wordCount) => {
    const checksumBitsPerWord = 3;
    return (wordCount / checksumBitsPerWord) * 32;
};
exports.entropyInBitsFromWordCount = entropyInBitsFromWordCount;
const byteCountFromEntropyStrength = (strenght) => strenght.valueOf() / 8;
exports.byteCountFromEntropyStrength = byteCountFromEntropyStrength;
const create = (input) => {
    const wordCount = input.words.length;
    return (0, exports.strengthFromWordCount)(wordCount)
        .andThen((strengthFromWC) => {
        if (strengthFromWC !== input.strength) {
            const errMsg = `Mismatch between 'words' and 'strenght'.`;
            util_1.log.error(errMsg);
            return (0, neverthrow_1.err)(new Error(errMsg));
        }
        if ((0, exports.entropyInBitsFromWordCount)(wordCount) !==
            input.entropy.length * 8) {
            const errMsg = `Mismatch 'words' and 'entropy'.`;
            util_1.log.error(errMsg);
            return (0, neverthrow_1.err)(new Error(errMsg));
        }
        if ((0, exports.byteCountFromEntropyStrength)(input.strength) !==
            input.entropy.length) {
            const errMsg = `Mismatch 'strength' and 'entropy'.`;
            util_1.log.error(errMsg);
            return (0, neverthrow_1.err)(new Error(errMsg));
        }
        const wordlist = (0, exports.wordlistFromLanguage)(input.language);
        const languageName = _types_1.LanguageT[input.language];
        if (input.words.join(separator) !== input.phrase) {
            const errMsg = `Mismatch between 'words' and 'phrase' ('phrase' possible non normalized (NFKD).).`;
            util_1.log.error(errMsg);
            return (0, neverthrow_1.err)(new Error(errMsg));
        }
        for (const word of input.words) {
            if (!wordlist.includes(word)) {
                const errMsg = `Mismatch between 'words' and 'language'`;
                util_1.log.error(errMsg);
                util_1.log.debug(`The word '${word}' was not found in mnemonic word list for language '${languageName}'`);
                return (0, neverthrow_1.err)(new Error(errMsg));
            }
        }
        return (0, neverthrow_1.ok)({ witness: 'valid input' });
    })
        .map((_) => (Object.assign(Object.assign({}, input), { toString: () => input.phrase, equals: (other) => (0, util_1.buffersEquals)(input.entropy, other.entropy) })))
        .map(mnemonic => {
        util_1.log.debug(`Successfully created mnemonic.`);
        return mnemonic;
    });
};
const fromEntropyAndMaybeStrength = (input) => {
    var _a;
    const language = (_a = input === null || input === void 0 ? void 0 : input.language) !== null && _a !== void 0 ? _a : _types_1.LanguageT.ENGLISH;
    const wordlist = (0, exports.wordlistFromLanguage)(language);
    const phrase = (0, bip39_1.entropyToMnemonic)(input.entropy, wordlist);
    if (!(0, bip39_1.validateMnemonic)(phrase, wordlist))
        throw new Error('Incorrect implementation, should be able to always generate valid mnemonic');
    const normalizedPhrase = phrase.normalize('NFKD');
    const words = normalizedPhrase.split(separator);
    const strengthOf = input.strength !== undefined
        ? (0, neverthrow_1.ok)(input.strength)
        : (0, exports.strengthFromWordCount)(words.length);
    return strengthOf.andThen(strength => create(Object.assign(Object.assign({}, input), { language,
        strength, phrase: normalizedPhrase, words })));
};
const fromEntropy = (input) => fromEntropyAndMaybeStrength(input);
const generateNew = (input) => {
    var _a, _b;
    const strength = (_a = input === null || input === void 0 ? void 0 : input.strength) !== null && _a !== void 0 ? _a : _types_1.StrengthT.WORD_COUNT_12;
    const secureRandom = (_b = input === null || input === void 0 ? void 0 : input.secureRandom) !== null && _b !== void 0 ? _b : util_1.secureRandomGenerator;
    const entropyByteCount = (0, exports.byteCountFromEntropyStrength)(strength);
    const entropy = Buffer.from(secureRandom.randomSecureBytes(entropyByteCount), 'hex');
    return fromEntropyAndMaybeStrength(Object.assign(Object.assign({}, input), { entropy,
        strength }))._unsafeUnwrap();
};
const fromPhraseInLanguage = (input) => {
    const wordlist = (0, exports.wordlistFromLanguage)(input.language);
    const phrase = input.phrase;
    let entropy;
    try {
        entropy = Buffer.from((0, bip39_1.mnemonicToEntropy)(phrase, wordlist), 'hex');
    }
    catch (e) {
        const errMsg = (0, util_1.msgFromError)(e);
        if (errMsg === 'Invalid mnemonic checksum') {
            const notChecksummedErr = 'Invalid mnemonic, it is not checksummed.';
            util_1.log.error(notChecksummedErr);
            return (0, neverthrow_1.err)(new Error(notChecksummedErr));
        }
        return (0, neverthrow_1.err)(e);
    }
    const normalizedPhrase = phrase.normalize('NFKD');
    const words = normalizedPhrase.split(separator);
    return (0, exports.strengthFromWordCount)(words.length)
        .map(strength => (Object.assign(Object.assign({}, input), { phrase: normalizedPhrase, words,
        entropy,
        strength })))
        .andThen(create);
};
const fromWordsInLanguage = (input) => fromPhraseInLanguage({
    phrase: input.words.join(separator),
    language: input.language,
});
const fromEnglishPhrase = (phrase) => fromPhraseInLanguage({
    phrase,
    language: _types_1.LanguageT.ENGLISH,
});
const fromEnglishWords = (words) => fromWordsInLanguage({
    words,
    language: _types_1.LanguageT.ENGLISH,
});
exports.Mnemonic = {
    generateNew,
    fromEntropy,
    fromPhraseInLanguage,
    fromWordsInLanguage,
    fromEnglishPhrase,
    fromEnglishWords,
};
//# sourceMappingURL=mnemonic.js.map